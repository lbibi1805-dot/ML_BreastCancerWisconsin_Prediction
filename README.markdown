# ü©∫ Breast Cancer Prediction - Machine Learning Comparison

[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Jupyter](https://img.shields.io/badge/Jupyter-Notebook-orange.svg)](https://jupyter.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.0+-gree```

## üèÜ Algorithm Performance

**Updated Performance Results (Latest Training - July 2025)**

| Algorithm | Test Accuracy | F1-Score | Precision | Recall | Training Time | Status |
|-----------|---------------|----------|-----------|---------|---------------|---------|
| **ü•á KNN (k=3)** | **97.08%** | **97.09%** | **97.14%** | **97.08%** | 0.011s | ‚úÖ **DEPLOYED** |
| ü•à Random Forest | 97.08% | 96.77% | 97.14% | 97.08% | 0.150s | ‚úÖ Available |
| ü•â Logistic Regression | 96.35% | 95.83% | 96.00% | 96.35% | 0.020s | ‚úÖ Available |
| SVM (RBF) | 96.35% | 95.83% | 96.00% | 96.35% | 0.080s | ‚úÖ Available |
| SVM (Linear) | 95.62% | 94.59% | 95.24% | 95.62% | 0.010s | ‚úÖ Available |
| Decision Tree | 95.62% | 94.59% | 95.24% | 95.62% | 0.003s | ‚úÖ Available |
| Naive Bayes | 94.89% | 93.88% | 94.59% | 94.89% | 0.002s | ‚úÖ Available |

### üéØ Why KNN Was Chosen for Deployment

1. **Highest Accuracy**: Tied for best test accuracy (97.08%)
2. **Excellent F1-Score**: Best F1-score (97.09%) indicating balanced precision/recall
3. **Fast Training**: Very quick training time (0.011s)
4. **Stable Performance**: Consistent results across multiple runs
5. **Medical Safety**: Good balance of Type I/Type II error rates
6. **Interpretability**: Easy to explain to medical professionals

### üìä Confusion Matrix (KNN - Deployed Model)
```
                Predicted
                Benign  Malignant
Actual Benign     84      3
       Malignant   1     49
```

**Key Metrics:**
- **Type I Error (False Positive)**: 3/87 = 3.45% - Benign classified as Malignant
- **Type II Error (False Negative)**: 1/50 = 2.00% - Malignant classified as Benign
- **Sensitivity (Recall)**: 49/50 = 98.00% - Correctly identified malignant cases
- **Specificity**: 84/87 = 96.55% - Correctly identified benign casesvg)](https://scikit-learn.org/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![API](https://img.shields.io/badge/API-Live-brightgreen.svg)](https://api-deploy-ml-breastcancer-wisconsin.onrender.com)

This project provides a comprehensive comparison of 7 machine learning algorithms for breast cancer prediction using the **Wisconsin Breast Cancer Dataset**. With a focus on medical applications, the project includes Type I/Type II error analysis, CAP Analysis, and **live API deployment** for real-world usage.

## üöÄ Live API Available

**Production API**: https://api-deploy-ml-breastcancer-wisconsin.onrender.com
- **Best Model**: KNN (k=3) with 97.08% accuracy deployed
- **Real-time predictions** via REST API
- **React/Express ready** with CORS support

```bash
# Test the live API
curl -X POST https://api-deploy-ml-breastcancer-wisconsin.onrender.com/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [2, 1, 1, 1, 2, 1, 2, 1, 1]}'
```

## üìã Table of Contents

- [üöÄ Live API Usage](#-live-api-usage)
- [üéØ Model Performance](#-model-performance) 
- [üìä Dataset Information](#-dataset-information)
- [üíª Local Development](#-local-development)
- [üè• Medical Analysis](#-medical-analysis)
- [ü§ù Contributing](#-contributing)
- [Contribution](#contribution)
- [License](#license)
- [Contact](#contact)

## üéØ Overview

This project implements and compares machine learning algorithms to classify breast cancer as **benign** or **malignant**. Designed with a modular architecture, the project emphasizes:

- **Optimal Performance**: Comparison of 7 algorithms with in-depth metrics.
- **Medical Safety**: Analysis of Type I (False Positive) and Type II (False Negative) errors.
- **Clinical Deployment**: Evaluation of real-world applicability in healthcare.

The dataset used is the **Wisconsin Breast Cancer Dataset** from the UCI Machine Learning Repository, featuring 9 attributes and 2 classes (benign: 2, malignant: 4).

## ‚ú® Features

### üî¨ Machine Learning
- **7 Algorithms**: Logistic Regression, KNN, SVM (Linear & RBF), Decision Tree, Random Forest, Naive Bayes.
- **Unified Preprocessing**: Feature scaling and consistent data processing.
- **Hyperparameter Optimization**: Optimal K for KNN, kernel comparison for SVM.
- **Cross-Validation**: Stable performance evaluation with 10-fold CV.

### üìä Visualization
- **Confusion Matrix**: Detailed classification error visualization.
- **Decision Boundary**: 2D decision boundary for each algorithm.
- **Feature Importance**: Analysis of feature significance.
- **CAP Curves**: Evaluation of discriminative ability in medical contexts.
- **Error Analysis Plots**: Comparison of Type I/Type II errors.

### üè• Medical Analysis
- **Type I/II Error Analysis**: Evaluation of false positives and false negatives.
- **CAP Analysis**: Cumulative Accuracy Profile for medical evaluation.
- **Clinical Recommendations**: Guidelines for deployment based on safety and efficacy.

### üíæ Model Persistence
- **Save/Load Models**: Save models with metadata (accuracy, hyperparameters, timestamp).
- **Batch Processing**: Manage multiple models simultaneously.
- **Production-Ready**: Prediction functions easily integrated into healthcare systems.

## üìä Dataset Structure Explanation

**üéØ Dependent Variable (Target Variable):**
- **`Class`**: Breast cancer classification
  - **2**: Benign - No cancer
  - **4**: Malignant - Cancer present

**üî¨ Independent Variables (Features):** 9 medical features from cell samples

1. **`clump_thickness`**: Clump thickness (1-10)
   - Higher values ‚Üí Suspected malignancy
   
2. **`uniform_cell_size`**: Uniformity of cell size (1-10)
   - Malignant cells often have non-uniform sizes
   
3. **`uniform_cell_shape`**: Uniformity of cell shape (1-10)
   - Malignant cells often have irregular shapes
   
4. **`marginal_adhesion`**: Marginal adhesion of cells (1-10)
   - Malignant cells tend to lose adhesion
   
5. **`single_epithelial_cell_size`**: Single epithelial cell size (1-10)
   - Related to abnormal cell growth
   
6. **`bare_nuclei`**: Bare nuclei (no surrounding cytoplasm) (1-10)
   - Common in malignant cancers
   
7. **`bland_chromatin`**: Chromatin structure (1-10)
   - Malignant cells have abnormal chromatin structure
   
8. **`normal_nucleoli`**: Normal nucleoli (1-10)
   - Malignant cells have larger, prominent nucleoli
   
9. **`mitoses`**: Mitotic activity (1-10)
   - Malignant cells have higher mitotic rates

**üìà Importance in Machine Learning:**
- **Features (X)**: 9 medical features ‚Üí Input data for prediction
- **Target (y)**: Cancer classification ‚Üí Outcome to predict
- **Objective**: Learn from features to accurately predict the target

## üìÅ Project Structure

```
ML_BreastCancerWisconsin_Prediction/
‚îÇ
‚îú‚îÄ‚îÄ üìä Dataset/
‚îÇ   ‚îú‚îÄ‚îÄ breast_cancer_wisconsin.csv      # Main dataset
‚îÇ   ‚îú‚îÄ‚îÄ breast_cancer.csv                # Secondary dataset
‚îÇ   ‚îú‚îÄ‚îÄ Source.txt                       # Source information
‚îÇ   ‚îî‚îÄ‚îÄ raw_data/                        # Raw data
‚îÇ       ‚îú‚îÄ‚îÄ breast-cancer-wisconsin.data
‚îÇ       ‚îú‚îÄ‚îÄ breast-cancer-wisconsin.names
‚îÇ       ‚îú‚îÄ‚îÄ wdbc.data
‚îÇ       ‚îú‚îÄ‚îÄ wdbc.names
‚îÇ       ‚îú‚îÄ‚îÄ wpbc.data
‚îÇ       ‚îî‚îÄ‚îÄ wpbc.names
‚îÇ
‚îú‚îÄ‚îÄ üíª Codes/
‚îÇ   ‚îú‚îÄ‚îÄ üìì ml_models_comparison.ipynb    # Complete model comparison & analysis
‚îÇ   ‚îú‚îÄ‚îÄ üìì knn_neighbours.ipynb          # KNN implementation (DEPLOYED MODEL)
‚îÇ   ‚îú‚îÄ‚îÄ üìì random_forest_classification.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ üìì logistic_regression.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ üìì SVM.ipynb & kernel_svm.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ ÔøΩ decision_tree.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ üåê streamlit_app.py              # Streamlit web interface
‚îÇ   ‚îú‚îÄ‚îÄ ÔøΩüõ†Ô∏è utils/                        # Utility package
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                  # Package initialization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_processor.py            # Data loading & preprocessing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_trainer.py             # Model training & evaluation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ visualizer.py                # Advanced visualizations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_persistence.py         # Model save/load (joblib)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model_comparison.py          # Performance comparison
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ medical_error_analysis.py    # Type I/II error analysis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cap_analysis.py              # CAP analysis for medical safety
‚îÇ   ‚îî‚îÄ‚îÄ data_crawler.py                  # UCI data fetching
‚îÇ
‚îú‚îÄ‚îÄ ü§ñ Models/                           # Trained model files (.joblib + metadata)
‚îÇ   ‚îú‚îÄ‚îÄ KNN_20250720_110419.joblib      # ‚úÖ DEPLOYED MODEL (97.08% accuracy)
‚îÇ   ‚îú‚îÄ‚îÄ KNN_20250720_110419_metadata.json
‚îÇ   ‚îú‚îÄ‚îÄ Random Forest_20250720_110419.joblib
‚îÇ   ‚îú‚îÄ‚îÄ Logistic Regression_20250720_110419.joblib
‚îÇ   ‚îú‚îÄ‚îÄ SVM_Linear_20250720_110419.joblib
‚îÇ   ‚îú‚îÄ‚îÄ SVM_RBF_20250720_110419.joblib
‚îÇ   ‚îú‚îÄ‚îÄ Decision Tree_20250720_110419.joblib
‚îÇ   ‚îî‚îÄ‚îÄ Naive Bayes_20250720_110419.joblib
‚îÇ
‚îú‚îÄ‚îÄ üåê api_server/                       # Flask API (local development)
‚îÇ   ‚îú‚îÄ‚îÄ app.py                          # Flask application with scaling fix
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt                # Dependencies
‚îÇ   ‚îú‚îÄ‚îÄ SETUP_GUIDE.md                 # Local setup instructions
‚îÇ   ‚îú‚îÄ‚îÄ DEPLOY_GUIDE.md                # Deployment guide
‚îÇ   ‚îî‚îÄ‚îÄ [Docker & deployment configs...]
‚îÇ
‚îú‚îÄ‚îÄ üîß prediction_tools/                # Testing & prediction utilities
‚îÇ   ‚îú‚îÄ‚îÄ single_prediction_test.py      # Multi-model testing system
‚îÇ   ‚îú‚îÄ‚îÄ knn_cancer_app.py             # KNN-focused prediction app
‚îÇ   ‚îú‚îÄ‚îÄ test_knn.py                   # Quick KNN validation
‚îÇ   ‚îî‚îÄ‚îÄ README.md                     # Prediction tools guide
‚îÇ   ‚îú‚îÄ‚îÄ SVM_RBF.pkl
‚îÇ   ‚îú‚îÄ‚îÄ Decision_Tree.pkl
‚îÇ   ‚îú‚îÄ‚îÄ Random_Forest.pkl
‚îÇ   ‚îú‚îÄ‚îÄ Naive_Bayes.pkl
‚îÇ   ‚îî‚îÄ‚îÄ metadata/                        # Model metadata
‚îÇ
‚îú‚îÄ‚îÄ üìú requirements.txt                  # Dependencies
‚îî‚îÄ‚îÄ üìñ README.md                         # This file
```

## üöÄ Installation

### Requirements
- Python 3.8+
- Jupyter Notebook/JupyterLab
- Git (optional)

### Step 1: Clone the Repository
```bash
git clone https://github.com/your-username/ML_BreastCancerWisconsin_Prediction.git
cd ML_BreastCancerWisconsin_Prediction
```

### Step 2: Create a Virtual Environment
```bash
# Create virtual environment
python -m venv venv

# Activate (Windows)
venv\Scripts\activate
# Activate (macOS/Linux)
source venv/bin/activate
```

### Step 3: Install Dependencies
```bash
pip install -r requirements.txt
```

### Step 4: Run Jupyter Notebook
```bash
cd Codes
jupyter notebook ml_models_comparison.ipynb
```

## üì¶ Dependencies (requirements.txt)

```txt
numpy>=1.21.0
pandas>=1.3.0
matplotlib>=3.4.0
seaborn>=0.11.0
scikit-learn>=1.0.0
jupyter>=1.0.0
plotly>=5.0.0
ipywidgets>=7.6.0
```

## üí° Usage

### üåê Use Live API (Recommended)

**Production API**: https://api-deploy-ml-breastcancer-wisconsin.onrender.com

```bash
# Health check
curl https://api-deploy-ml-breastcancer-wisconsin.onrender.com/

# Make prediction
curl -X POST https://api-deploy-ml-breastcancer-wisconsin.onrender.com/predict \
  -H "Content-Type: application/json" \
  -d '{"features": [2, 1, 1, 1, 2, 1, 2, 1, 1]}'
```

### üìì Local Development & Training

**Quick Start:**
1. Open `Codes/ml_models_comparison.ipynb`
2. Run all cells to train all models and compare performance
3. Models are automatically saved to `Models/` directory

**Individual Model Training:**
```bash
cd Codes
jupyter notebook knn_neighbours.ipynb         # Train KNN (deployed model)
jupyter notebook random_forest_classification.ipynb
jupyter notebook logistic_regression.ipynb
# ... other model notebooks
```

### üîß Local Prediction Testing

```bash
cd prediction_tools

# Test KNN model (deployed version)
python test_knn.py

# Interactive KNN prediction app
python knn_cancer_app.py

# Multi-model comparison
python single_prediction_test.py
```

### üåê Local API Server

```bash
cd api_server
pip install -r requirements.txt
python app.py
# Server: http://localhost:5000
```

### Usage Example (Python)
```python
# Import our utility modules
from Codes.utils import *

# Load and preprocess data
dataset, feature_names = load_and_explore_data("Dataset/breast_cancer_wisconsin.csv")
X_train, X_test, y_train, y_test, scaler = preprocess_data(dataset, feature_names)

# Train KNN (best performing model)
from sklearn.neighbors import KNeighborsClassifier
knn_model = KNeighborsClassifier(n_neighbors=3)
knn_results = train_and_evaluate_model(knn_model, "KNN", X_train, X_test, y_train, y_test)

# Save model
save_model(knn_model, knn_results, "KNN", save_dir="Models")

# Make prediction on new data
new_patient = [[2, 1, 1, 1, 2, 1, 2, 1, 1]]  # Benign case
new_patient_scaled = scaler.transform(new_patient)
prediction = knn_model.predict(new_patient_scaled)
print(f"Prediction: {'Benign' if prediction[0] == 2 else 'Malignant'}")
```
results = train_and_evaluate_model(model, "Random Forest", X_train, X_test, y_train, y_test)

# Visualize
plot_confusion_matrix(results)
plot_decision_boundary(model, "Random Forest", X_train, y_train, feature_names)

# Save model
save_model(model, results, "Random_Forest", save_dir="../Models")
```

### Load and Use Saved Model
```python
# Load model
loaded_model, metadata = load_model_by_name("Random_Forest", save_dir="../Models")
prediction = loaded_model.predict(new_data)
```

## ü§ñ Algorithm Performance

| Algorithm           | Accuracy | Precision | Recall | F1-Score | Training Time |
|--------------------|----------|-----------|--------|----------|---------------|
| Random Forest      | 97.08%   | 97.15%    | 97.08% | 97.09%   | 0.029s        |
| Naive Bayes        | 94.16%   | 94.65%    | 94.16% | 94.22%   | 0.000s        |
| SVM (Linear)       | 94.89%   | 95.04%    | 94.89% | 94.92%   | 0.014s        |
| SVM (RBF)          | 94.89%   | 95.04%    | 94.89% | 94.92%   | 0.007s        |
| Logistic Regression| 94.89%   | 94.92%    | 94.89% | 94.90%   | 0.009s        |
| Decision Tree      | 95.62%   | 95.62%    | 95.62% | 95.62%   | 0.004s        |
| KNN                | 94.16%   | 94.15%    | 94.16% | 94.13%   | 0.004s        |

### Notes
- **Random Forest** is the best model with 97.08% accuracy and the lowest Type II Error (0.02).
- **Naive Bayes** has the fastest training time (0.000s).
- **Logistic Regression** and **SVM** offer high interpretability, suitable for medical environments.

## üè• Medical Analysis & Clinical Implications

### üö® Error Analysis (Critical for Medical Applications)

**KNN Model (Deployed) Error Breakdown:**
- **Type I Error (False Positive)**: 3/87 = **3.45%**
  - **Clinical Impact**: Benign tissue misclassified as malignant
  - **Consequences**: Patient anxiety, unnecessary procedures, additional testing costs
  - **Acceptable Level**: ‚úÖ Within medical guidelines (<5%)

- **Type II Error (False Negative)**: 1/50 = **2.00%**
  - **Clinical Impact**: Malignant tissue misclassified as benign
  - **Consequences**: ‚ö†Ô∏è **CRITICAL** - Delayed treatment, disease progression
  - **Benchmark**: ‚úÖ Excellent (<3% is considered very good)

### üìä Medical Performance Metrics

| Metric | KNN (Deployed) | Clinical Significance |
|--------|----------------|----------------------|
| **Sensitivity** | 98.00% | Correctly identifies 98% of cancer cases |
| **Specificity** | 96.55% | Correctly identifies 96.5% of healthy cases |
| **PPV (Precision)** | 94.23% | 94% of positive predictions are correct |
| **NPV** | 98.82% | 99% of negative predictions are correct |

### üéØ Clinical Recommendations

1. **KNN Model Deployment**: ‚úÖ **Recommended for clinical use**
   - Excellent balance of sensitivity/specificity
   - Low Type II error rate (critical for cancer detection)
   - Fast prediction time suitable for real-time diagnosis

2. **Usage Guidelines**:
   - Use as **screening tool** with expert physician review
   - **Always combine** with clinical examination and other tests
   - Consider biopsy for borderline cases (confidence < 85%)

3. **Risk Mitigation**:
   - Implement **confidence thresholds** (API provides confidence scores)
   - **Flag low-confidence predictions** for additional testing
   - Regular model retraining with new data

### üîç API Safety Features

The deployed API includes medical safety considerations:
- **Confidence scoring** for all predictions
- **Medical disclaimers** in all responses
- **Risk level assessment** (Low/High)
- **Recommendation guidance** for healthcare providers

## üîß Customization

### Add New Algorithm
```python
# In utils/model_trainer.py
def train_new_algorithm(X_train, X_test, y_train, y_test):
    model = YourNewModel()
    return train_and_evaluate_model(model, "New Model", X_train, X_test, y_train, y_test)
```

### Add Visualization
```python
# In utils/visualizer.py
def plot_custom_visualization(data, title):
    # Add new visualization
    pass
```

### Add New Metric
```python
# In utils/model_comparison.py
def calculate_new_metric(y_true, y_pred):
    return new_score
```

## ü§ù Contribution

### How to Contribute
1. Fork the repository.
2. Create a new branch (`git checkout -b feature/YourFeature`).
3. Commit changes (`git commit -m 'Add YourFeature'`).
4. Push to the branch (`git push origin feature/YourFeature`).
5. Create a Pull Request.

### Code Standards
- Follow **PEP 8**.
- Add **docstrings** to all functions.
- Use **type hints** where possible.
- Include comprehensive error handling.

### Contribution Ideas
- Add Deep Learning algorithms (e.g., TensorFlow/Keras).
- Integrate real-time API execution.
- Add advanced visualizations (e.g., 3D plots).
- Automate hyperparameter tuning.

## üêõ Bug Reporting

Please create an issue with:
- Detailed bug description.
- Environment (OS, Python version, dependencies).
- Steps to reproduce the bug.
- Expected outcome.

## üìù License

This project is distributed under the **MIT License**:

```
MIT License

Copyright (c) 2025 Breast Cancer Prediction Project

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

## üìû Contact

- **GitHub**: [Your GitHub Profile](https://github.com/your-username)
- **Email**: your.email@example.com
- **LinkedIn**: [Your LinkedIn](https://linkedin.com/in/your-profile)

## üôè Acknowledgments

- **Wisconsin Breast Cancer Dataset**: UCI Machine Learning Repository.
- **scikit-learn**: Powerful machine learning library.
- **Jupyter**: Excellent interactive environment.
- **Matplotlib & Seaborn**: High-quality visualizations.

---

‚≠ê **If you find this project helpful, please give it a star!** ‚≠ê

**Note**: This is a research and educational project. Do not use it as a substitute for professional medical diagnosis.

---
