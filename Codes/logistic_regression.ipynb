{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q8X8xDwS6vgS"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PEGG4I6n60cM"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Aa536pRY7Eq5"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('../Dataset/breast_cancer_wisconsin.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Information\n",
            "__________________________\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 699 entries, 0 to 698\n",
            "Data columns (total 10 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   Clump_thickness              699 non-null    int64  \n",
            " 1   Uniformity_of_cell_size      699 non-null    int64  \n",
            " 2   Uniformity_of_cell_shape     699 non-null    int64  \n",
            " 3   Marginal_adhesion            699 non-null    int64  \n",
            " 4   Single_epithelial_cell_size  699 non-null    int64  \n",
            " 5   Bare_nuclei                  683 non-null    float64\n",
            " 6   Bland_chromatin              699 non-null    int64  \n",
            " 7   Normal_nucleoli              699 non-null    int64  \n",
            " 8   Mitoses                      699 non-null    int64  \n",
            " 9   Class                        699 non-null    int64  \n",
            "dtypes: float64(1), int64(9)\n",
            "memory usage: 54.7 KB\n",
            "None\n",
            "Dataset raw data\n",
            "\n",
            "___________________________\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 699 entries, 0 to 698\n",
            "Data columns (total 10 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   Clump_thickness              699 non-null    int64  \n",
            " 1   Uniformity_of_cell_size      699 non-null    int64  \n",
            " 2   Uniformity_of_cell_shape     699 non-null    int64  \n",
            " 3   Marginal_adhesion            699 non-null    int64  \n",
            " 4   Single_epithelial_cell_size  699 non-null    int64  \n",
            " 5   Bare_nuclei                  683 non-null    float64\n",
            " 6   Bland_chromatin              699 non-null    int64  \n",
            " 7   Normal_nucleoli              699 non-null    int64  \n",
            " 8   Mitoses                      699 non-null    int64  \n",
            " 9   Class                        699 non-null    int64  \n",
            "dtypes: float64(1), int64(9)\n",
            "memory usage: 54.7 KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset Information\");\n",
        "print(\"__________________________\")\n",
        "print(dataset.info());\n",
        "\n",
        "print(\"Dataset raw data\\n\");\n",
        "print(\"___________________________\")\n",
        "print(dataset_raw.info());"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Declare features and dependant variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On the features, remove the \"Sample code number\" because it is not relevant to the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 1.  1.  1. ...  3.  1.  1.]\n",
            " [ 4.  4.  5. ...  3.  2.  1.]\n",
            " [ 1.  1.  1. ...  3.  1.  1.]\n",
            " ...\n",
            " [10. 10.  3. ...  8. 10.  2.]\n",
            " [ 8.  6.  4. ... 10.  6.  1.]\n",
            " [ 8.  8.  5. ... 10.  4.  1.]]\n"
          ]
        }
      ],
      "source": [
        "X = dataset.iloc[:,1:-1].values;\n",
        "print(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2 2 2 2 2 4 2 2 2 2 2 2 4 2 4 4 2 2 4 2 4 4 2 4 2 4 2 2 2 2 2 2 4 2 2 2 4\n",
            " 2 4 4 2 4 4 4 4 2 4 2 2 4 4 4 4 4 4 4 4 4 4 4 4 2 4 4 2 4 2 4 4 2 2 4 2 4\n",
            " 4 2 2 2 2 2 2 2 2 2 4 4 4 4 2 2 2 2 2 2 2 2 2 2 4 4 4 4 2 4 4 4 4 4 2 4 2\n",
            " 4 4 4 2 2 2 4 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 2 2 2 2 2 2 2 2 2 4 2 2 2 4 2\n",
            " 2 4 2 4 4 2 2 4 2 2 2 4 4 2 2 2 2 2 4 4 2 2 2 2 2 4 4 4 2 4 2 4 2 2 2 4 4\n",
            " 2 4 4 4 2 4 4 2 2 2 2 2 2 2 2 4 4 2 2 2 4 4 2 2 2 4 4 2 4 4 4 2 2 4 2 2 4\n",
            " 4 4 4 2 4 4 2 4 4 4 2 4 2 2 4 4 4 4 2 2 2 2 2 2 4 4 2 2 2 4 2 4 4 4 2 2 2\n",
            " 2 4 4 4 4 4 2 4 4 4 2 4 2 4 4 2 2 2 2 2 4 2 2 4 4 4 4 4 2 4 4 2 2 4 4 2 4\n",
            " 2 2 2 4 4 2 4 2 4 4 2 2 4 2 2 2 4 2 2 2 4 4 2 2 4 2 2 4 2 2 4 2 4 4 4 2 2\n",
            " 4 4 2 4 2 2 4 4 2 2 2 4 2 2 2 4 4 2 2 2 4 2 2 4 4 4 4 4 4 2 2 2 2 4 4 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 4 2 2 2 2 4 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2\n",
            " 2 2 2 2 2 4 2 4 2 4 2 2 2 2 4 2 2 2 4 2 4 2 2 2 2 2 2 2 4 4 2 2 2 4 2 2 2\n",
            " 2 2 2 2 2 4 2 2 2 4 2 4 4 4 2 2 2 2 2 2 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 4 2\n",
            " 2 4 4 2 2 2 4 4 4 2 4 2 4 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 4 4 2 2\n",
            " 2 4 2 2 4 4 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2 4 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 4 2 2 4 4 4 4 2 2 4 2 2 2 2 2 2 4 4 2 2 2 4 2 4 2 4 4\n",
            " 4 2 4 2 2 2 2 2 2 2 2 4 4 4 2 2 4 2 4 4 4 2 2 2 2 2 2 2 2 2 2 2 2 2 4 2 2\n",
            " 2 2 2 2 4 2 2 4 2 2 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2 2 2 4 2 2 2 2 2 2 2\n",
            " 2 2 4 4 4 2 2 2 2 2 2 2 2 2 4 4 2 2 2 2 2 2 2 2 2 4 2 2 2 2 4 4 4]\n"
          ]
        }
      ],
      "source": [
        "y = dataset.iloc[:, -1].values;\n",
        "print(y);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0AnzJQCj7TLO"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataSet Splitting:\n",
            "\n",
            "_______________________________\n",
            "X_train:  4472\n",
            "X_test:  1120\n",
            "y_train: 559\n",
            "y_test 140\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split;\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0);\n",
        "\n",
        "print(\"DataSet Splitting:\\n\");\n",
        "print(\"_______________________________\")\n",
        "print(\"X_train: \", np.size(X_train));\n",
        "print(\"X_test: \", np.size(X_test));\n",
        "print(\"y_train:\", np.size(y_train));\n",
        "print(\"y_test\", np.size(y_test));\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pS1Q-n_A7iZ_"
      },
      "source": [
        "## Training the Logistic Regression model on the Training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4cgD7EnB8Dnd"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "26CHkZbs8Tu5"
      },
      "source": [
        "## Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kMErnLnu8hmb"
      },
      "source": [
        "## Computing the accuracy with k-Fold Cross Validation"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Logistic Regression",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
