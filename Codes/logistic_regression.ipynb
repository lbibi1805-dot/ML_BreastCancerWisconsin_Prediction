{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q8X8xDwS6vgS"
      },
      "source": [
        "# Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "PEGG4I6n60cM"
      },
      "source": [
        "## Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Aa536pRY7Eq5"
      },
      "source": [
        "## Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = pd.read_csv('../Dataset/breast_cancer_wisconsin.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset Information\n",
            "__________________________\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 699 entries, 0 to 698\n",
            "Data columns (total 10 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   Clump_thickness              699 non-null    int64  \n",
            " 1   Uniformity_of_cell_size      699 non-null    int64  \n",
            " 2   Uniformity_of_cell_shape     699 non-null    int64  \n",
            " 3   Marginal_adhesion            699 non-null    int64  \n",
            " 4   Single_epithelial_cell_size  699 non-null    int64  \n",
            " 5   Bare_nuclei                  683 non-null    float64\n",
            " 6   Bland_chromatin              699 non-null    int64  \n",
            " 7   Normal_nucleoli              699 non-null    int64  \n",
            " 8   Mitoses                      699 non-null    int64  \n",
            " 9   Class                        699 non-null    int64  \n",
            "dtypes: float64(1), int64(9)\n",
            "memory usage: 54.7 KB\n",
            "None\n",
            "\n",
            "\n",
            "Number of null data:\n",
            "\n",
            "__________________________\n",
            "Clump_thickness                 0\n",
            "Uniformity_of_cell_size         0\n",
            "Uniformity_of_cell_shape        0\n",
            "Marginal_adhesion               0\n",
            "Single_epithelial_cell_size     0\n",
            "Bare_nuclei                    16\n",
            "Bland_chromatin                 0\n",
            "Normal_nucleoli                 0\n",
            "Mitoses                         0\n",
            "Class                           0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(\"Dataset Information\");\n",
        "print(\"__________________________\")\n",
        "pprint(dataset.info());\n",
        "print(\"\\n\")\n",
        "print(\"Number of null data:\\n\")\n",
        "print(\"__________________________\")\n",
        "pprint(pd.isnull(dataset).sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Proccess null value:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of null data:\n",
            "\n",
            "__________________________\n",
            "Clump_thickness                0\n",
            "Uniformity_of_cell_size        0\n",
            "Uniformity_of_cell_shape       0\n",
            "Marginal_adhesion              0\n",
            "Single_epithelial_cell_size    0\n",
            "Bare_nuclei                    0\n",
            "Bland_chromatin                0\n",
            "Normal_nucleoli                0\n",
            "Mitoses                        0\n",
            "Class                          0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "threshold = 0.05;\n",
        "\n",
        "if dataset.isna().sum().sum() / dataset.size < threshold:\n",
        "    dataset = dataset.dropna()\n",
        "else:\n",
        "    for col in dataset.columns:\n",
        "        if dataset[col].dtype in ['float64', 'int64']:\n",
        "            # Điền NaN bằng mean cho dữ liệu số\n",
        "            dataset[col] = dataset[col].fillna(dataset[col].mean())\n",
        "        else:\n",
        "            # Điền NaN bằng giá trị phổ biến nhất cho dữ liệu dạng object/categorical\n",
        "            dataset[col] = dataset[col].fillna(dataset[col].mode()[0])\n",
        "\n",
        "print(\"Number of null data:\\n\")\n",
        "print(\"__________________________\")\n",
        "pprint(pd.isnull(dataset).sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Declare features and dependant variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On the features, remove the \"Sample code number\" because it is not relevant to the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "array([[ 1.,  1.,  1., ...,  3.,  1.,  1.],\n",
            "       [ 4.,  4.,  5., ...,  3.,  2.,  1.],\n",
            "       [ 1.,  1.,  1., ...,  3.,  1.,  1.],\n",
            "       ...,\n",
            "       [10., 10.,  3., ...,  8., 10.,  2.],\n",
            "       [ 8.,  6.,  4., ..., 10.,  6.,  1.],\n",
            "       [ 8.,  8.,  5., ..., 10.,  4.,  1.]])\n"
          ]
        }
      ],
      "source": [
        "X = dataset.iloc[:,1:-1].values;\n",
        "pprint(X)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "array([2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 2, 4, 4,\n",
            "       2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 4, 2, 4, 4, 4,\n",
            "       4, 2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 2, 4, 4, 2, 4,\n",
            "       2, 4, 4, 2, 2, 4, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 4,\n",
            "       2, 4, 4, 4, 2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 4, 2, 4, 2, 4, 2, 2, 2,\n",
            "       4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 2,\n",
            "       2, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 4,\n",
            "       2, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 4, 4, 2, 4, 4, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 4, 4, 2, 4, 4, 4, 2, 2, 4, 2,\n",
            "       2, 4, 4, 4, 4, 2, 4, 4, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 2,\n",
            "       2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2, 2, 4, 4, 4, 4,\n",
            "       4, 2, 4, 4, 4, 2, 4, 2, 4, 4, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 4, 4,\n",
            "       4, 2, 4, 4, 2, 2, 4, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2,\n",
            "       4, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 4, 4,\n",
            "       4, 2, 2, 4, 4, 2, 4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 2,\n",
            "       2, 4, 2, 2, 4, 4, 4, 4, 4, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2,\n",
            "       2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 4, 2,\n",
            "       2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2,\n",
            "       4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2, 2,\n",
            "       2, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4,\n",
            "       2, 2, 2, 4, 4, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
            "       4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2,\n",
            "       2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 4, 4,\n",
            "       2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 4, 2,\n",
            "       4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4,\n",
            "       2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 4], dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "y = dataset.iloc[:, -1].values;\n",
        "pprint(y);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0AnzJQCj7TLO"
      },
      "source": [
        "## Splitting the dataset into the Training set and Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataSet Splitting:\n",
            "\n",
            "_______________________________\n",
            "X_train:  4368\n",
            "X_test:  1096\n",
            "y_train: 546\n",
            "y_test 137\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split;\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0);\n",
        "\n",
        "print(\"DataSet Splitting:\\n\");\n",
        "print(\"_______________________________\")\n",
        "print(\"X_train: \", np.size(X_train));\n",
        "print(\"X_test: \", np.size(X_test));\n",
        "print(\"y_train:\", np.size(y_train));\n",
        "print(\"y_test\", np.size(y_test));\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pS1Q-n_A7iZ_"
      },
      "source": [
        "## Training the Logistic Regression model on the Training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression;\n",
        "classifier = LogisticRegression(random_state=0);\n",
        "classifier.fit(X_train, y_train);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4cgD7EnB8Dnd"
      },
      "source": [
        "## Predicting the Test set results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "array([2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 2, 4, 4, 4, 4, 2, 2, 2,\n",
            "       4, 2, 4, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 2,\n",
            "       2, 2, 2, 4, 2, 2, 4, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 2,\n",
            "       2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 4, 2, 2, 4, 2, 4,\n",
            "       4, 2, 4, 2, 4, 4, 2, 4, 4, 4, 4, 2, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2,\n",
            "       4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 2, 4, 2, 4, 2, 2,\n",
            "       4, 2, 2, 4, 2], dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "y_pred = classifier.predict(X_test);\n",
        "pprint(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "26CHkZbs8Tu5"
      },
      "source": [
        "## Making the Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "array([[83,  4],\n",
            "       [ 3, 47]], dtype=int64)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix;\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred);\n",
        "pprint(cm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kMErnLnu8hmb"
      },
      "source": [
        "## Computing the accuracy with k-Fold Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracies:   96.6969696969697  %\n",
            "Standard Deviation:   2.4347159649944254  %\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score;\n",
        "\n",
        "accuracies = cross_val_score(estimator=classifier, X=X_train, y=y_train, cv=10);\n",
        "print(\"Accuracies:  \", format(accuracies.mean() * 100), \" %\")\n",
        "print(\"Standard Deviation:  \", format(accuracies.std() * 100), \" %\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Logistic Regression",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
